#!/usr/bin/env python3
"""
load_data.pyã®å‹•ä½œã‚’ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§æ¤œè¨¼ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å„æ®µéšã§å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã«åŸå› ã‚’ç‰¹å®šã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆ
"""

import os
import sys
import traceback
from typing import Any, Tuple

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append("dinov2")

import torch
import numpy as np
from PIL import Image
from functools import partial

# DINOv2é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from dinov2.data.augmentations import DataAugmentationDINO, DataAugmentationDINOMRI
from dinov2.data.collate import collate_data_and_cast
from dinov2.data.masking import MaskingGenerator
from dinov2.data.loaders import make_data_loader, SamplerType
from dinov2.train.ssl_meta_arch import SSLMetaArch
from dinov2.utils.config import setup
import dinov2.distributed as distributed

# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from load_data import MriDataset

def step1_basic_dataset_test(nii_path: str) -> bool:
    """
    ã‚¹ãƒ†ãƒƒãƒ—1: MriDatasetã®åŸºæœ¬å‹•ä½œç¢ºèª
    """
    print("\n" + "="*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—1: MriDatasetã®åŸºæœ¬å‹•ä½œç¢ºèª")
    print("="*60)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­: {nii_path}")
        dataset = MriDataset(nii_path)
        
        # åŸºæœ¬æƒ…å ±ç¢ºèª
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆæˆåŠŸ")
        print(f"  ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé•·: {len(dataset)}")
        print(f"  MRIãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {dataset.mri_data.shape}")
        
        # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«å–å¾—
        print(f"æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«å–å¾—ä¸­...")
        sample_image, sample_target = dataset[0]
        
        # çµæœç¢ºèª
        print(f"âœ“ ã‚µãƒ³ãƒ—ãƒ«å–å¾—æˆåŠŸ")
        print(f"  ç”»åƒå‹: {type(sample_image)}")
        print(f"  ç”»åƒã‚µã‚¤ã‚º: {sample_image.size}")
        print(f"  ç”»åƒãƒ¢ãƒ¼ãƒ‰: {sample_image.mode}")
        print(f"  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {sample_target}")
        print(f"  ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå‹: {type(sample_target)}")
        
        # è¤‡æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
        print(f"è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®ç¢ºèª...")
        for i in [0, len(dataset)//2, len(dataset)-1]:
            try:
                img, tgt = dataset[i]
                print(f"  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {i}: ç”»åƒã‚µã‚¤ã‚º={img.size}, ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ={tgt}")
            except Exception as e:
                print(f"  âœ— ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ {i} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                return False
        
        print(f"âœ“ ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: åŸºæœ¬å‹•ä½œç¢ºèªæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— ã‚¹ãƒ†ãƒƒãƒ—1å¤±æ•—: {e}")
        traceback.print_exc()
        return False


def step2_data_augmentation_test(nii_path: str) -> bool:
    """
    ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å‹•ä½œç¢ºèª
    """
    print("\n" + "="*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å‹•ä½œç¢ºèª")
    print("="*60)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãªã—ï¼‰
        dataset = MriDataset(nii_path)
        
        # MRIç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®ä½œæˆ
        print("MRIç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ä½œæˆä¸­...")
        data_transform = DataAugmentationDINOMRI(
            global_crops_scale=(0.32, 1.0),
            local_crops_scale=(0.05, 0.32),
            local_crops_number=8,
            global_crops_size=896,
            local_crops_size=256,
        )
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µä½œæˆæˆåŠŸ")
        
        # æ‹¡å¼µå‰ã®ç”»åƒ
        original_image, _ = dataset[0]
        print(f"æ‹¡å¼µå‰ç”»åƒ: ã‚µã‚¤ã‚º={original_image.size}, ãƒ¢ãƒ¼ãƒ‰={original_image.mode}")
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨
        print("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨ä¸­...")
        augmented_data = data_transform(original_image)
        
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨æˆåŠŸ")
        print(f"  æ‹¡å¼µå¾Œã®ãƒ‡ãƒ¼ã‚¿å‹: {type(augmented_data)}")
        
        if isinstance(augmented_data, dict):
            for key, value in augmented_data.items():
                if isinstance(value, list):
                    print(f"  {key}: ãƒªã‚¹ãƒˆ (é•·ã•={len(value)})")
                    for i, item in enumerate(value):
                        if hasattr(item, 'shape'):
                            print(f"    [{i}]: shape={item.shape}, dtype={item.dtype}")
                        else:
                            print(f"    [{i}]: {type(item)}")
                elif hasattr(value, 'shape'):
                    print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
                else:
                    print(f"  {key}: {type(value)}")
        
        print(f"âœ“ ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µç¢ºèªæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— ã‚¹ãƒ†ãƒƒãƒ—2å¤±æ•—: {e}")
        traceback.print_exc()
        return False


def step3_dataloader_test(nii_path: str) -> bool:
    """
    ã‚¹ãƒ†ãƒƒãƒ—3: DataLoaderã®å‹•ä½œç¢ºèª
    """
    print("\n" + "="*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—3: DataLoaderã®å‹•ä½œç¢ºèª")
    print("="*60)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        dataset = MriDataset(nii_path)
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®š
        data_transform = DataAugmentationDINOMRI(
            global_crops_scale=(0.32, 1.0),
            local_crops_scale=(0.05, 0.32),
            local_crops_number=8,
            global_crops_size=896,
            local_crops_size=256,
        )
        
        # ãƒã‚¹ã‚­ãƒ³ã‚°è¨­å®š
        img_size = 896
        patch_size = 16
        n_tokens = (img_size // patch_size) ** 2
        
        mask_generator = MaskingGenerator(
            input_size=(img_size // patch_size, img_size // patch_size),
            max_num_patches=0.5 * img_size // patch_size * img_size // patch_size,
        )
        
        # ã‚³ãƒ¬ãƒ¼ãƒˆé–¢æ•°è¨­å®š
        collate_fn = partial(
            collate_data_and_cast,
            mask_ratio_tuple=(0.1, 0.5),
            mask_probability=1.0,
            n_tokens=n_tokens,
            mask_generator=mask_generator,
            dtype=torch.float32,
        )
        
        # ä¿®æ­£ã•ã‚ŒãŸMriDatasetã‚¯ãƒ©ã‚¹ï¼ˆãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå¯¾å¿œï¼‰
        class MriDatasetWithTransform(MriDataset):
            def __init__(self, nii_path, transform=None):
                super().__init__(nii_path)
                self.transform = transform
            
            def __getitem__(self, idx):
                mri_slice = self.mri_data[:, :, idx]
                from load_data import numpy_to_pil
                pil_image = numpy_to_pil(mri_slice)
                
                # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨
                if self.transform:
                    pil_image = self.transform(pil_image)
                
                target = ()
                return pil_image, target
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†ä½œæˆï¼ˆå¤‰æ›ä»˜ãï¼‰
        dataset_with_transform = MriDatasetWithTransform(nii_path, transform=data_transform)
        
        print(f"DataLoaderä½œæˆä¸­...")
        data_loader = make_data_loader(
            dataset=dataset_with_transform,
            batch_size=1,
            num_workers=0,  # ã‚·ãƒ³ã‚°ãƒ«ãƒ—ãƒ­ã‚»ã‚¹ã§ãƒ†ã‚¹ãƒˆ
            shuffle=False,
            seed=0,
            sampler_type=SamplerType.EPOCH,
            sampler_size=5,  # å°‘æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ†ã‚¹ãƒˆ
            drop_last=False,
            collate_fn=collate_fn,
        )
        
        print(f"âœ“ DataLoaderä½œæˆæˆåŠŸ")
        print(f"  DataLoaderã®é•·ã•: {len(data_loader)}")
        
        # æœ€åˆã®ãƒãƒƒãƒå–å¾—
        print(f"æœ€åˆã®ãƒãƒƒãƒå–å¾—ä¸­...")
        data_iter = iter(data_loader)
        batch = next(data_iter)
        
        print(f"âœ“ ãƒãƒƒãƒå–å¾—æˆåŠŸ")
        print(f"  ãƒãƒƒãƒã®ã‚­ãƒ¼: {list(batch.keys())}")
        for key, value in batch.items():
            if hasattr(value, 'shape'):
                print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
            else:
                print(f"  {key}: {type(value)}")
        
        print(f"âœ“ ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†: DataLoaderç¢ºèªæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— ã‚¹ãƒ†ãƒƒãƒ—3å¤±æ•—: {e}")
        traceback.print_exc()
        return False


def step4_model_input_test(nii_path: str) -> bool:
    """
    ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ç¢ºèª
    """
    print("\n" + "="*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«ã¸ã®å…¥åŠ›ç¢ºèª")
    print("="*60)
    
    try:
        # ç°¡å˜ãªè¨­å®šä½œæˆ
        print("è¨­å®šä½œæˆä¸­...")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        class SimpleConfig:
            def __init__(self):
                self.crops = type('obj', (object,), {
                    'global_crops_size': 896,
                    'local_crops_size': 256,
                    'global_crops_scale': (0.32, 1.0),
                    'local_crops_scale': (0.05, 0.32),
                    'local_crops_number': 8
                })
                self.student = type('obj', (object,), {
                    'patch_size': 16,
                    'in_chans': 3,  # RGBå…¥åŠ›
                    'arch': 'vit_small',
                    'embed_dim': 384,
                    'depth': 12,
                    'num_heads': 6,
                    'mlp_ratio': 4.0,
                    'drop_path_rate': 0.1,
                    'drop_path_uniform': True,
                    'layerscale': 1.0e-4,
                    'block_chunks': 0
                })
                self.teacher = self.student
                self.dino = type('obj', (object,), {
                    'head_n_prototypes': 65536,
                    'head_bottleneck_dim': 256,
                    'head_nlayers': 3,
                    'head_hidden_dim': 2048,
                    'koleo_loss_weight': 0.1
                })
                self.ibot = type('obj', (object,), {
                    'mask_ratio_min_max': (0.1, 0.5),
                    'mask_sample_probability': 1.0,
                    'head_n_prototypes': 65536,
                    'head_bottleneck_dim': 256,
                    'head_nlayers': 3,
                    'head_hidden_dim': 2048
                })
                self.optim = type('obj', (object,), {
                    'epochs': 100,
                    'batch_size_per_gpu': 1,
                    'lr': 1e-4,
                    'clip_grad': 3.0
                })
                self.train = type('obj', (object,), {
                    'batch_size_per_gpu': 1,
                    'output_dir': './output',
                    'OFFICIAL_EPOCH_LENGTH': 1250
                })
        
        cfg = SimpleConfig()
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        print("ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸­...")
        model = SSLMetaArch(cfg).to(device)
        print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸ")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆã‚¹ãƒ†ãƒƒãƒ—3ã¨åŒæ§˜ï¼‰
        
        data_transform = DataAugmentationDINOMRI(
            global_crops_scale=(0.32, 1.0),
            local_crops_scale=(0.05, 0.32),
            local_crops_number=8,
            global_crops_size=896,
            local_crops_size=256,
        )
        
        img_size = 896
        patch_size = 16
        n_tokens = (img_size // patch_size) ** 2
        
        mask_generator = MaskingGenerator(
            input_size=(img_size // patch_size, img_size // patch_size),
            max_num_patches=0.5 * img_size // patch_size * img_size // patch_size,
        )
        
        collate_fn = partial(
            collate_data_and_cast,
            mask_ratio_tuple=(0.1, 0.5),
            mask_probability=1.0,
            n_tokens=n_tokens,
            mask_generator=mask_generator,
            dtype=torch.float32,
        )
        
        # ä¿®æ­£ã•ã‚ŒãŸMriDatasetã‚¯ãƒ©ã‚¹ï¼ˆå†å®šç¾©ï¼‰
        class MriDatasetWithTransform(MriDataset):
            def __init__(self, nii_path, transform=None):
                super().__init__(nii_path)
                self.transform = transform
            
            def __getitem__(self, idx):
                mri_slice = self.mri_data[:, :, idx]
                from load_data import numpy_to_pil
                pil_image = numpy_to_pil(mri_slice)
                
                if self.transform:
                    pil_image = self.transform(pil_image)
                
                return pil_image, ()
        
        dataset = MriDatasetWithTransform(nii_path, transform=data_transform)
        
        data_loader = make_data_loader(
            dataset=dataset,
            batch_size=1,
            num_workers=0,
            shuffle=False,
            seed=0,
            sampler_type=SamplerType.EPOCH,
            sampler_size=2,  # 2ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ãƒ†ã‚¹ãƒˆ
            drop_last=False,
            collate_fn=collate_fn,
        )
        
        # ãƒãƒƒãƒå–å¾—
        print("ãƒãƒƒãƒå–å¾—ä¸­...")
        data_iter = iter(data_loader)
        batch = next(data_iter)
        
        # ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›
        print("ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ä¸­...")
        model.eval()
        with torch.no_grad():
            try:
                # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹å®Ÿè¡Œ
                outputs = model(batch)
                print(f"âœ“ ãƒ¢ãƒ‡ãƒ«å…¥åŠ›æˆåŠŸ")
                print(f"  å‡ºåŠ›ã®å‹: {type(outputs)}")
                if isinstance(outputs, dict):
                    for key, value in outputs.items():
                        if hasattr(value, 'shape'):
                            print(f"  {key}: shape={value.shape}")
                        else:
                            print(f"  {key}: {type(value)}")
                
            except Exception as e:
                print(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§ã‚¨ãƒ©ãƒ¼: {e}")
                print("å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®è©³ç´°:")
                for key, value in batch.items():
                    if hasattr(value, 'shape'):
                        print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
                        if torch.is_tensor(value):
                            print(f"    min={value.min()}, max={value.max()}")
                raise
        
        print(f"âœ“ ã‚¹ãƒ†ãƒƒãƒ—4å®Œäº†: ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ç¢ºèªæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— ã‚¹ãƒ†ãƒƒãƒ—4å¤±æ•—: {e}")
        traceback.print_exc()
        return False


def step5_training_steps_test(nii_path: str) -> bool:
    """
    ã‚¹ãƒ†ãƒƒãƒ—5: å­¦ç¿’ã®æœ€åˆã®æ•°ã‚¹ãƒ†ãƒƒãƒ—ç¢ºèª
    """
    print("\n" + "="*60)
    print("ã‚¹ãƒ†ãƒƒãƒ—5: å­¦ç¿’ã®æœ€åˆã®æ•°ã‚¹ãƒ†ãƒƒãƒ—ç¢ºèª")
    print("="*60)
    
    try:
        print("å®Ÿéš›ã®å­¦ç¿’è¨­å®šã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # å®Ÿéš›ã®train_mri_simple.pyã®è¨­å®šã‚’ä½¿ç”¨
        import argparse
        from dinov2.train.train import get_args_parser
        
        # è¨­å®šèª­ã¿è¾¼ã¿
        sys.argv = [
            "test_script",
            "--config-file", "dinov2/dinov2/configs/ssl_default_config.yaml",
            "--output-dir", "./test_output",
        ]
        
        dinov2_args = get_args_parser().parse_args()
        cfg = setup(dinov2_args)
        
        # MRIç”¨ã®è¨­å®šèª¿æ•´
        cfg.crops.global_crops_size = 896
        cfg.crops.local_crops_size = 256
        cfg.train.batch_size_per_gpu = 1
        cfg.train.num_workers = 0
        cfg.optim.epochs = 1  # 1ã‚¨ãƒãƒƒã‚¯ã®ã¿
        
        print(f"âœ“ è¨­å®šèª­ã¿è¾¼ã¿æˆåŠŸ")
        
        # ç°¡å˜ãªå­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        print("ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸­...")
        model = SSLMetaArch(cfg).to(device)
        model.train()
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ä½œæˆ
        from dinov2.train.train import build_optimizer
        optimizer = build_optimizer(cfg, model.get_params_groups())
        
        print(f"âœ“ å­¦ç¿’æº–å‚™å®Œäº†")
        print(f"  ãƒ‡ãƒã‚¤ã‚¹: {device}")
        print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {cfg.train.batch_size_per_gpu}")
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆç°¡ç•¥ç‰ˆï¼‰
        print("ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆä¸­...")
        
        # å‰ã®ã‚¹ãƒ†ãƒƒãƒ—ã¨åŒã˜ãƒ‡ãƒ¼ã‚¿æº–å‚™
        data_transform = DataAugmentationDINOMRI(
            global_crops_scale=(0.32, 1.0),
            local_crops_scale=(0.05, 0.32),
            local_crops_number=8,
            global_crops_size=896,
            local_crops_size=256,
        )
        
        class MriDatasetWithTransform(MriDataset):
            def __init__(self, nii_path, transform=None):
                super().__init__(nii_path)
                self.transform = transform
            
            def __getitem__(self, idx):
                mri_slice = self.mri_data[:, :, idx]
                from load_data import numpy_to_pil
                pil_image = numpy_to_pil(mri_slice)
                
                if self.transform:
                    pil_image = self.transform(pil_image)
                
                return pil_image, ()
        
        dataset = MriDatasetWithTransform(nii_path, transform=data_transform)
        
        img_size = cfg.crops.global_crops_size
        patch_size = cfg.student.patch_size
        n_tokens = (img_size // patch_size) ** 2
        
        mask_generator = MaskingGenerator(
            input_size=(img_size // patch_size, img_size // patch_size),
            max_num_patches=0.5 * img_size // patch_size * img_size // patch_size,
        )
        
        collate_fn = partial(
            collate_data_and_cast,
            mask_ratio_tuple=cfg.ibot.mask_ratio_min_max,
            mask_probability=cfg.ibot.mask_sample_probability,
            n_tokens=n_tokens,
            mask_generator=mask_generator,
            dtype=torch.half if torch.cuda.is_available() else torch.float32,
        )
        
        data_loader = make_data_loader(
            dataset=dataset,
            batch_size=cfg.train.batch_size_per_gpu,
            num_workers=0,
            shuffle=True,
            seed=0,
            sampler_type=SamplerType.EPOCH,
            sampler_size=3,  # 3ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿ãƒ†ã‚¹ãƒˆ
            drop_last=True,
            collate_fn=collate_fn,
        )
        
        print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆæˆåŠŸ")
        
        # å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
        print("å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œä¸­...")
        
        step_count = 0
        max_steps = 3
        
        for batch in data_loader:
            if step_count >= max_steps:
                break
                
            print(f"  ã‚¹ãƒ†ãƒƒãƒ— {step_count + 1}/{max_steps}")
            
            try:
                # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ + ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰
                optimizer.zero_grad()
                
                loss_dict = model.forward_backward(batch, teacher_temp=0.04)
                
                # å‹¾é…è¨ˆç®—ç¢ºèª
                has_grads = False
                for name, param in model.named_parameters():
                    if param.grad is not None:
                        has_grads = True
                        break
                
                print(f"    âœ“ ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰/ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰æˆåŠŸ")
                print(f"    âœ“ å‹¾é…è¨ˆç®—: {'æˆåŠŸ' if has_grads else 'å¤±æ•—'}")
                
                # ãƒ­ã‚¹å€¤ç¢ºèª
                loss_values = {k: v.item() for k, v in loss_dict.items()}
                total_loss = sum(loss_values.values())
                print(f"    ç·ãƒ­ã‚¹: {total_loss:.6f}")
                for k, v in loss_values.items():
                    print(f"      {k}: {v:.6f}")
                
                # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—
                optimizer.step()
                print(f"    âœ“ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†")
                
                step_count += 1
                
            except Exception as e:
                print(f"    âœ— ã‚¹ãƒ†ãƒƒãƒ— {step_count + 1} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                raise
        
        print(f"âœ“ ã‚¹ãƒ†ãƒƒãƒ—5å®Œäº†: {step_count}ã‚¹ãƒ†ãƒƒãƒ—ã®å­¦ç¿’æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âœ— ã‚¹ãƒ†ãƒƒãƒ—5å¤±æ•—: {e}")
        traceback.print_exc()
        return False


def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    print("="*70)
    print("load_data.py ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("="*70)
    
    # MRIãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    default_nii_path = "/mnt/c/brain-segmentation/data/372/153035372/brats2025-gli-pre-challenge-trainingdata/BraTS2025-GLI-PRE-Challenge-TrainingData/BraTS-GLI-00000-000"
    
    # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    nii_path = None
    if os.path.exists(default_nii_path):
        for file in os.listdir(default_nii_path):
            if file.endswith(".nii.gz") and "seg" not in file:
                nii_path = os.path.join(default_nii_path, file)
                break
    
    if not nii_path or not os.path.exists(nii_path):
        print(f"âœ— MRIãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {default_nii_path}")
        print("ä½¿ç”¨æ–¹æ³•: python test_load_data_step_by_step.py [nii_file_path]")
        if len(sys.argv) > 1:
            nii_path = sys.argv[1]
            if not os.path.exists(nii_path):
                print(f"âœ— æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {nii_path}")
                return
        else:
            return
    
    print(f"ä½¿ç”¨ã™ã‚‹MRIãƒ•ã‚¡ã‚¤ãƒ«: {nii_path}")
    
    # å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ
    steps = [
        ("åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‹•ä½œ", step1_basic_dataset_test),
        ("ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ", step2_data_augmentation_test),
        ("DataLoader", step3_dataloader_test),
        ("ãƒ¢ãƒ‡ãƒ«å…¥åŠ›", step4_model_input_test),
        ("å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—", step5_training_steps_test),
    ]
    
    results = {}
    
    for step_name, step_func in steps:
        print(f"\n{'='*20} {step_name} {'='*20}")
        
        try:
            success = step_func(nii_path)
            results[step_name] = success
            
            if success:
                print(f"âœ“ {step_name}: æˆåŠŸ")
            else:
                print(f"âœ— {step_name}: å¤±æ•—")
                print("ä»¥é™ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                break
                
        except KeyboardInterrupt:
            print(f"\nä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
            break
        except Exception as e:
            print(f"âœ— {step_name}: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            results[step_name] = False
            break
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "="*70)
    print("æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
    print("="*70)
    
    for step_name, success in results.items():
        status = "âœ“ æˆåŠŸ" if success else "âœ— å¤±æ•—"
        print(f"{step_name:20}: {status}")
    
    # å…¨ä½“ã®æˆåŠŸç‡
    success_count = sum(results.values())
    total_count = len(results)
    success_rate = success_count / total_count if total_count > 0 else 0
    
    print(f"\næˆåŠŸç‡: {success_count}/{total_count} ({success_rate:.1%})")
    
    if success_rate == 1.0:
        print("\nğŸ‰ ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒæˆåŠŸã—ã¾ã—ãŸï¼train_mri_simple.pyã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")
    else:
        print(f"\nâš ï¸  ä¸€éƒ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®ã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main() 