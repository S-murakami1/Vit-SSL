#!/usr/bin/env python
"""
MRI DINOv2å­¦ç¿’ç”¨ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãƒ†ã‚¹ãƒˆã—ã€å•é¡Œã‚’ç‰¹å®šã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
python test.py --nii-path /path/to/your/mri.nii.gz [--auto] [--step N]

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
--auto: è‡ªå‹•å®Ÿè¡Œï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã§åœæ­¢ã—ãªã„ï¼‰
--step N: æŒ‡å®šã—ãŸã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰é–‹å§‹
--batch-size: ãƒ†ã‚¹ãƒˆç”¨ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰
"""

import argparse
import sys
import os
import traceback
import logging
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MRIDebugTester:
    def __init__(self, nii_path, batch_size=2, auto_mode=False):
        self.nii_path = nii_path
        self.batch_size = batch_size
        self.auto_mode = auto_mode
        self.current_step = 0
        self.test_results = {}
        
    def log_step(self, step_num, description):
        """ã‚¹ãƒ†ãƒƒãƒ—ã®é–‹å§‹ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
        print(f"\n{'='*60}")
        print(f"ã‚¹ãƒ†ãƒƒãƒ— {step_num}: {description}")
        print(f"{'='*60}")
        self.current_step = step_num
        
    def wait_for_user(self, message="æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã¿ã¾ã™ã‹ï¼Ÿ [y/n/q]: "):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å¾…ã¤ï¼ˆè‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã§ãªã„å ´åˆï¼‰"""
        if self.auto_mode:
            return True
            
        while True:
            response = input(message).lower().strip()
            if response in ['y', 'yes', '']:
                return True
            elif response in ['n', 'no']:
                return False
            elif response in ['q', 'quit', 'exit']:
                print("ãƒ†ã‚¹ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                sys.exit(0)
            else:
                print("y/n/q ã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    def test_step_1_basic_imports(self):
        """ã‚¹ãƒ†ãƒƒãƒ—1: åŸºæœ¬çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        self.log_step(1, "åŸºæœ¬çš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
        
        try:
            # åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
            import torch
            import numpy as np
            from PIL import Image
            import nibabel as nib
            
            print(f"âœ“ PyTorch version: {torch.__version__}")
            print(f"âœ“ CUDA available: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"âœ“ CUDA device: {torch.cuda.get_device_name()}")
                print(f"âœ“ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
            
            print(f"âœ“ NumPy version: {np.__version__}")
            print(f"âœ“ PIL version: {Image.__version__}")
            print(f"âœ“ nibabel version: {nib.__version__}")
            
            self.test_results[1] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[1] = f"FAILED: {e}"
            return False
    
    def test_step_2_load_data(self):
        """ã‚¹ãƒ†ãƒƒãƒ—2: load_data.pyã®ãƒ†ã‚¹ãƒˆ"""
        self.log_step(2, "load_data.pyã®MriDatasetãƒ†ã‚¹ãƒˆ")
        
        try:
            # load_data.pyã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from load_data import MriDataset, numpy_to_pil
            
            print(f"âœ“ load_data.pyã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            
            # MRIãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(self.nii_path):
                raise FileNotFoundError(f"MRIãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.nii_path}")
            
            print(f"âœ“ MRIãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {self.nii_path}")
            
            # MriDatasetã®ä½œæˆ
            dataset = MriDataset(self.nii_path)
            print(f"âœ“ MriDatasetä½œæˆæˆåŠŸ")
            print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)} ã‚¹ãƒ©ã‚¤ã‚¹")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            sample_image, sample_target = dataset[0]
            print(f"âœ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ")
            print(f"  - Image type: {type(sample_image)}")
            print(f"  - Image size: {sample_image.size}")
            print(f"  - Image mode: {sample_image.mode}")
            print(f"  - Target: {sample_target}")
            
            self.dataset = dataset  # å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨
            self.test_results[2] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— load_data.pyãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[2] = f"FAILED: {e}"
            return False
    
    def test_step_3_dinov2_imports(self):
        """ã‚¹ãƒ†ãƒƒãƒ—3: DINOv2é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        self.log_step(3, "DINOv2é–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ")
        
        try:
            # DINOv2ã®åŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from dinov2.data import DataAugmentationDINO, MaskingGenerator, collate_data_and_cast
            print("âœ“ dinov2.dataåŸºæœ¬ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            
            # MRIç”¨ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from dinov2.data.loaders_mri import make_data_loader, make_dataset, SamplerType
            print("âœ“ dinov2.data.loaders_mriã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            
            # å­¦ç¿’é–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from dinov2.train.ssl_meta_arch import SSLMetaArch
            print("âœ“ dinov2.train.ssl_meta_archã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            
            # è¨­å®šé–¢é€£ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from dinov2.utils.config import setup
            print("âœ“ dinov2.utils.configã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            
            self.test_results[3] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— DINOv2ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[3] = f"FAILED: {e}"
            return False
    
    def test_step_4_config_loading(self):
        """ã‚¹ãƒ†ãƒƒãƒ—4: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
        self.log_step(4, "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ")
        
        try:
            import argparse
            from dinov2.utils.config import setup
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ç¢ºèª
            config_path = "dinov2/dinov2/configs/ssl_mri_vits_config.yaml"
            if not os.path.exists(config_path):
                raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
            
            print(f"âœ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª: {config_path}")
            
            # å¼•æ•°ã®æº–å‚™
            class MockArgs:
                def __init__(self):
                    self.config_file = config_path
                    self.opts = [
                        f"train.dataset_path=MriDataset:path={self.nii_path}",
                        "train.output_dir=./test_output",
                        f"train.batch_size_per_gpu={self.batch_size}"
                    ]
            
            args = MockArgs()
            
            # è¨­å®šã®èª­ã¿è¾¼ã¿
            cfg = setup(args)
            print("âœ“ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            
            # é‡è¦ãªè¨­å®šé …ç›®ã®ç¢ºèª
            print(f"  - Student arch: {cfg.student.arch}")
            print(f"  - Patch size: {cfg.student.patch_size}")
            print(f"  - Global crop size: {cfg.crops.global_crops_size}")
            print(f"  - Batch size: {cfg.train.batch_size_per_gpu}")
            print(f"  - Dataset path: {cfg.train.dataset_path}")
            
            self.cfg = cfg  # å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨
            self.test_results[4] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[4] = f"FAILED: {e}"
            return False
    
    def test_step_5_data_loader(self):
        """ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆãƒ†ã‚¹ãƒˆ"""
        self.log_step(5, "ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆãƒ†ã‚¹ãƒˆ")
        
        try:
            from dinov2.data import DataAugmentationDINO, MaskingGenerator
            from dinov2.data.loaders_mri import make_data_loader, make_dataset, SamplerType
            from functools import partial
            from dinov2.data import collate_data_and_cast
            
            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®æº–å‚™
            data_transform = DataAugmentationDINO(
                self.cfg.crops.global_crops_scale,
                self.cfg.crops.local_crops_scale,
                self.cfg.crops.local_crops_number,
                global_crops_size=self.cfg.crops.global_crops_size,
                local_crops_size=self.cfg.crops.local_crops_size,
            )
            print("âœ“ ãƒ‡ãƒ¼ã‚¿å¤‰æ›è¨­å®šæˆåŠŸ")
            
            # ãƒã‚¹ã‚¯ç”Ÿæˆå™¨ã®æº–å‚™
            img_size = self.cfg.crops.global_crops_size
            patch_size = self.cfg.student.patch_size
            n_tokens = (img_size // patch_size) ** 2
            
            mask_generator = MaskingGenerator(
                input_size=(img_size // patch_size, img_size // patch_size),
                max_num_patches=0.5 * img_size // patch_size * img_size // patch_size,
            )
            print("âœ“ ãƒã‚¹ã‚¯ç”Ÿæˆå™¨è¨­å®šæˆåŠŸ")
            
            # ã‚³ãƒ¬ãƒ¼ãƒˆé–¢æ•°ã®æº–å‚™
            collate_fn = partial(
                collate_data_and_cast,
                mask_ratio_tuple=self.cfg.ibot.mask_ratio_min_max,
                mask_probability=self.cfg.ibot.mask_sample_probability,
                n_tokens=n_tokens,
                mask_generator=mask_generator,
                dtype=torch.half,
            )
            print("âœ“ ã‚³ãƒ¬ãƒ¼ãƒˆé–¢æ•°è¨­å®šæˆåŠŸ")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
            dataset = make_dataset(
                dataset_str=self.cfg.train.dataset_path,
                transform=data_transform,
                target_transform=lambda _: (),
            )
            print(f"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆæˆåŠŸ: {len(dataset)} ã‚µãƒ³ãƒ—ãƒ«")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
            data_loader = make_data_loader(
                dataset=dataset,
                batch_size=self.batch_size,
                num_workers=2,  # ãƒ†ã‚¹ãƒˆç”¨ã«å‰Šæ¸›
                shuffle=True,
                seed=42,
                sampler_type=SamplerType.INFINITE,
                sampler_advance=0,
                drop_last=True,
                collate_fn=collate_fn,
            )
            print("âœ“ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆæˆåŠŸ")
            
            self.data_loader = data_loader  # å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨
            self.test_results[5] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[5] = f"FAILED: {e}"
            return False
    
    def test_step_6_model_creation(self):
        """ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ"""
        self.log_step(6, "ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ†ã‚¹ãƒˆ")
        
        try:
            import torch
            from dinov2.train.ssl_meta_arch import SSLMetaArch
            
            # GPUç¢ºèª
            if not torch.cuda.is_available():
                print("âš  CUDAä¸ä½¿ç”¨ã§ãƒ†ã‚¹ãƒˆã‚’ç¶šè¡Œã—ã¾ã™")
                device = torch.device("cpu")
            else:
                device = torch.device("cuda")
                print(f"âœ“ CUDAä½¿ç”¨: {torch.cuda.get_device_name()}")
            
            # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
            model = SSLMetaArch(self.cfg).to(device)
            print("âœ“ SSLMetaArchãƒ¢ãƒ‡ãƒ«ä½œæˆæˆåŠŸ")
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
            total_params = sum(p.numel() for p in model.parameters())
            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
            
            print(f"  - Total parameters: {total_params:,}")
            print(f"  - Trainable parameters: {trainable_params:,}")
            print(f"  - Model device: {next(model.parameters()).device}")
            
            self.model = model  # å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨
            self.device = device
            self.test_results[6] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— ãƒ¢ãƒ‡ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[6] = f"FAILED: {e}"
            return False
    
    def test_step_7_data_batch(self):
        """ã‚¹ãƒ†ãƒƒãƒ—7: ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—ãƒ†ã‚¹ãƒˆ"""
        self.log_step(7, "ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—ãƒ†ã‚¹ãƒˆ")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰1ãƒãƒƒãƒå–å¾—
            data_iter = iter(self.data_loader)
            batch = next(data_iter)
            
            print("âœ“ ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—æˆåŠŸ")
            print(f"  - Batch keys: {list(batch.keys())}")
            
            if "collated_global_crops" in batch:
                global_crops = batch["collated_global_crops"]
                print(f"  - Global crops shape: {global_crops.shape}")
                print(f"  - Global crops dtype: {global_crops.dtype}")
                print(f"  - Global crops device: {global_crops.device}")
            
            if "collated_local_crops" in batch:
                local_crops = batch["collated_local_crops"]
                print(f"  - Local crops shape: {local_crops.shape}")
                print(f"  - Local crops dtype: {local_crops.dtype}")
            
            self.sample_batch = batch  # å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨
            self.test_results[7] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[7] = f"FAILED: {e}"
            return False
    
    def test_step_8_forward_pass(self):
        """ã‚¹ãƒ†ãƒƒãƒ—8: ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ãƒ†ã‚¹ãƒˆ"""
        self.log_step(8, "ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ãƒ†ã‚¹ãƒˆ")
        
        try:
            # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
            self.model.train()
            
            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹å®Ÿè¡Œ
            with torch.cuda.amp.autocast(enabled=True):
                loss_dict = self.model.forward_backward(self.sample_batch, teacher_temp=0.04)
            
            print("âœ“ ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹æˆåŠŸ")
            print(f"  - Loss keys: {list(loss_dict.keys())}")
            
            for key, value in loss_dict.items():
                print(f"  - {key}: {value.item():.6f}")
            
            # ç·æå¤±è¨ˆç®—
            total_loss = sum(loss_dict.values())
            print(f"  - Total loss: {total_loss.item():.6f}")
            
            # NaNç¢ºèª
            if any(torch.isnan(v) for v in loss_dict.values()):
                print("âš  NaN detected in losses!")
                return False
            
            self.test_results[8] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[8] = f"FAILED: {e}"
            return False
    
    def test_step_9_optimizer_step(self):
        """ã‚¹ãƒ†ãƒƒãƒ—9: ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ"""
        self.log_step(9, "ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ")
        
        try:
            import torch.optim as optim
            
            # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ä½œæˆ
            params_groups = self.model.get_params_groups()
            optimizer = optim.AdamW(
                params_groups, 
                betas=(self.cfg.optim.adamw_beta1, self.cfg.optim.adamw_beta2)
            )
            
            print("âœ“ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ä½œæˆæˆåŠŸ")
            
            # ã‚°ãƒ©ãƒ‡ã‚£ã‚¨ãƒ³ãƒˆç¢ºèª
            total_grad_norm = 0
            param_count = 0
            for param in self.model.parameters():
                if param.grad is not None:
                    param_norm = param.grad.data.norm(2)
                    total_grad_norm += param_norm.item() ** 2
                    param_count += 1
            
            total_grad_norm = total_grad_norm ** (1. / 2)
            print(f"  - Gradient norm: {total_grad_norm:.6f}")
            print(f"  - Parameters with gradients: {param_count}")
            
            # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—
            optimizer.step()
            optimizer.zero_grad()
            
            print("âœ“ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—æˆåŠŸ")
            
            self.test_results[9] = "SUCCESS"
            return True
            
        except Exception as e:
            print(f"âœ— ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚¹ãƒ†ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            self.test_results[9] = f"FAILED: {e}"
            return False
    
    def print_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print(f"\n{'='*60}")
        print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*60}")
        
        for step, result in self.test_results.items():
            status = "âœ“" if result == "SUCCESS" else "âœ—"
            print(f"ã‚¹ãƒ†ãƒƒãƒ— {step}: {status} {result}")
        
        successful_steps = sum(1 for result in self.test_results.values() if result == "SUCCESS")
        total_steps = len(self.test_results)
        
        print(f"\næˆåŠŸ: {successful_steps}/{total_steps} ã‚¹ãƒ†ãƒƒãƒ—")
        
        if successful_steps == total_steps:
            print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼å­¦ç¿’ã‚’é–‹å§‹ã§ãã¾ã™ã€‚")
        else:
            print(f"\nâš  {total_steps - successful_steps} å€‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
    
    def run_tests(self, start_step=1):
        """ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
        test_methods = [
            self.test_step_1_basic_imports,
            self.test_step_2_load_data,
            self.test_step_3_dinov2_imports,
            self.test_step_4_config_loading,
            self.test_step_5_data_loader,
            self.test_step_6_model_creation,
            self.test_step_7_data_batch,
            self.test_step_8_forward_pass,
            self.test_step_9_optimizer_step,
        ]
        
        for i, test_method in enumerate(test_methods[start_step-1:], start=start_step):
            success = test_method()
            
            if not success:
                print(f"\nã‚¹ãƒ†ãƒƒãƒ— {i} ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
                if not self.wait_for_user("ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ã—ã¦ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ [y/n/q]: "):
                    break
            elif i < len(test_methods):
                if not self.wait_for_user():
                    break
        
        self.print_summary()


def main():
    parser = argparse.ArgumentParser(description='MRI DINOv2 Debug Tester')
    parser.add_argument('--nii-path', required=True, type=str,
                       help='Path to MRI .nii.gz file for testing')
    parser.add_argument('--auto', action='store_true',
                       help='Run all tests automatically without user prompts')
    parser.add_argument('--step', type=int, default=1, choices=range(1, 10),
                       help='Start from specific step (1-9)')
    parser.add_argument('--batch-size', type=int, default=2,
                       help='Batch size for testing (default: 2)')
    
    args = parser.parse_args()
    
    print("MRI DINOv2 ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 40)
    print(f"MRIãƒ•ã‚¡ã‚¤ãƒ«: {args.nii_path}")
    print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {args.batch_size}")
    print(f"è‡ªå‹•å®Ÿè¡Œ: {'Yes' if args.auto else 'No'}")
    print(f"é–‹å§‹ã‚¹ãƒ†ãƒƒãƒ—: {args.step}")
    
    if not args.auto:
        print("\nå„ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿè¡Œã‚’ä¸€æ™‚åœæ­¢ã—ã¾ã™ã€‚")
        print("y: æ¬¡ã¸, n: ã‚¹ã‚­ãƒƒãƒ—, q: çµ‚äº†")
    
    tester = MRIDebugTester(
        nii_path=args.nii_path,
        batch_size=args.batch_size,
        auto_mode=args.auto
    )
    
    tester.run_tests(start_step=args.step)


if __name__ == "__main__":
    main() 